{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import datetime, time ,date ,timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import seaborn as sns\n",
    "import gc\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "from datetime import date\n",
    "today = date.today().strftime(\"%Y%m%d\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten (table):\n",
    "    if type(table.columns)==pd.MultiIndex:\n",
    "        columns_to_look = [name_tmp for name_tmp in table.columns]\n",
    "\n",
    "        columns_df = [ str(t[0])+'_'+str(t[1]) for t in columns_to_look]\n",
    "        columns_df.insert(0,table.index.name)\n",
    "\n",
    "        df = pd.DataFrame(columns = columns_df)\n",
    "\n",
    "        index = 0\n",
    "        for i in table.index:\n",
    "            row = [table[r][i] for r in columns_to_look]\n",
    "            row.insert(0,i)\n",
    "            df.loc[index] = row\n",
    "            index = index + 1\n",
    "        return(df)\n",
    "    else :\n",
    "        table = pd.DataFrame(table)\n",
    "        table.reset_index(level=0, inplace=True)\n",
    "        return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "repertoire = 'C:/Users/pierrick/eleven/Engagements - Vertbaudet/3. Data received/3. Extract/1. France/SEGSTRAT'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEG_STRAT to csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a csv with the field IDIND - NUMCDE - DATCDE - SEGMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_zero(x):\n",
    "    if x[-2] == '0':\n",
    "        return x[:-2]+x[-1]\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-1a81d34743b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepertoire\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mfile_name_tmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepertoire\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mdf_seg_tmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name_tmp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m\"unicode_escape\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mdf_seg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_seg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf_seg_tmp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;32mdel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_seg_tmp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1897\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1898\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1899\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1900\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Invalid argument"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "for year in range(2017,2022):\n",
    "    print(year)\n",
    "    gc.collect()\n",
    "    df_tmp = pd.read_csv('./Vertbaudet/France/src/Original/Lignes_commandes/Export_FR_LIGNECOMMANDE_'+str(year)+'.csv', \n",
    "                              encoding = 'unicode_escape', \n",
    "                              usecols = ['IDIND', 'NUMCDE', 'DATCDE'])\n",
    "    \n",
    "    df_tmp = df_tmp.replace({'$null$': np.nan})\n",
    "    df_tmp['DATCDE'] = pd.to_datetime(df_tmp['DATCDE'])\n",
    "    df_tmp['IDIND'] = df_tmp['IDIND'].astype(float)\n",
    "    \n",
    "    ### Load segments\n",
    "    repertoire = 'C:/Users/pierrick/eleven/Engagements - Vertbaudet/3. Data received/3. Extract/1. France/SEGSTRAT/'+str(year)\n",
    "    df_seg = pd.DataFrame()\n",
    "    for file in os.listdir(repertoire):\n",
    "        file_name_tmp = os.path.join(repertoire,file)\n",
    "        df_seg_tmp = pd.read_csv(file_name_tmp,sep=\",\",encoding= \"unicode_escape\")\n",
    "        df_seg = pd.concat([df_seg,df_seg_tmp])\n",
    "        del(df_seg_tmp)\n",
    "    \n",
    "    ### Format segments  \n",
    "    df_seg = df_seg[df_seg['PERIODE_MENS'] != '$null$']\n",
    "    df_seg.PERIODE_MENS = df_seg.PERIODE_MENS.astype(int)\n",
    "    df_seg.PERIODE_MENS = df_seg.PERIODE_MENS.astype(str)\n",
    "    df_seg = df_seg.drop_duplicates(subset = ['IDIND', 'PERIODE_MENS'])\n",
    "    df_seg = df_seg.groupby(['IDIND', 'PERIODE_MENS']).agg({'SEG_STRAT': 'first'}).unstack()\n",
    "    df_seg = df_seg.droplevel(level = 0, axis = 1)\n",
    "    \n",
    "    if '$null$' in df_seg.columns:\n",
    "        df_seg = df_seg.drop(columns = '$null$')\n",
    "    gc.collect()\n",
    "    \n",
    "    df_seg.columns = list(map(remove_zero,df_seg.columns))\n",
    "    if '$null$' in df_seg.index:\n",
    "        df_seg = df_seg.drop(index = '$null$')\n",
    "    df_seg_index = df_seg.index.astype(float)\n",
    "    \n",
    "    \n",
    "    ### Compute segment column\n",
    "    list_month = list(map(lambda x : int(x[4:]), df_seg.columns))\n",
    "\n",
    "    def map_seg(x):\n",
    "        if x[0] in df_seg.index:\n",
    "            for month in list_month:\n",
    "                if x[1] <= date(year, month, 28):\n",
    "                    return df_seg[str(year)+str(month)][x[0]]\n",
    "                    break\n",
    "            return np.nan\n",
    "        else:\n",
    "            return np.nan\n",
    "        \n",
    "    df_tmp['SEGMENT'] = df_tmp[['IDIND', 'DATCDE']].apply(map_seg, axis = 1)\n",
    "    \n",
    "    df = pd.concat([df,df_tmp])\n",
    "  \n",
    "    del df_tmp\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./Vertbaudet/France/src/SEGFR.CSV')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_articles = pd.read_csv('./Vertbaudet/France/src/Original/Articles/Export_FR_Articles_Julie.csv',\n",
    "                                     usecols = [\"DEPARTEMENT_NIV2\",\"CODSAI\",\"REFSTK\", \"TOP_MN_Max\"])\n",
    "\n",
    "df_codsoc = pd.read_csv('./Vertbaudet/France/src/20210921_CODSOC.csv')\n",
    "\n",
    "df_client_dept = pd.read_csv('./20210923_Export_tab_FR/20210921_INDIVIDUS.tab', sep = '\\t',\n",
    "                 usecols = ['IDIND', 'CODPOST', \"DATPREMCDEWEB\"])\n",
    "\n",
    "clients_mag = pd.read_csv(\"./Vertbaudet/France/src/20211004_UNIQUE_IDIND_TICKET.csv\",sep=\",\")\n",
    "\n",
    "df_client = pd.read_csv('./Vertbaudet/France/Output_old/iris_med_rev_clients.csv', usecols = ['IDIND', 'Mediane'])\n",
    "\n",
    "df_IRIS_by_dep = pd.read_excel('./Vertbaudet/France/INSEE_data/INSEE_IRIS_by_dep.xlsx', usecols = ['CODGEO','MED18'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "267"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "df = pd.DataFrame()\n",
    "for year in range(2017,2022):\n",
    "    print(year)\n",
    "    gc.collect()\n",
    "    df_tmp = pd.read_csv('./Vertbaudet/France/src/Original/Lignes_commandes/Export_FR_LIGNECOMMANDE_'+str(year)+'.csv', \n",
    "                              encoding = 'unicode_escape', \n",
    "                              usecols = ['IDIND', 'IDCLI', 'IDFOYER', 'DATCDE', 'DN', 'DBI', 'QTE', 'NUMCDE', 'CODSAI','REFSTK'])\n",
    "    \n",
    "    ### df_evt_tclub\n",
    "    df_evt_tclub = pd.read_csv('C:/Users/pierrick/eleven/Engagements - Vertbaudet/3. Data received/3. Extract/1. France/20211022_TYPEVT_'+str(year)[2:]+'.csv')\n",
    "    df_tmp = df_tmp.merge(df_evt_tclub, how = 'left', on = ['IDCLI', 'DATCDE', 'REFSTK', 'CODSAI', 'NUMCDE'])\n",
    "    del df_evt_tclub\n",
    "    gc.collect()\n",
    "    \n",
    "    \n",
    "    ### Merge with article table to get DEPARTEMENT_NIV2\n",
    "    df_tmp = df_tmp.merge(df_articles, how = 'left', on = [\"CODSAI\",\"REFSTK\"])\n",
    "    \n",
    "    ### Replace $null$\n",
    "    df_tmp = df_tmp.replace({'$null$': np.nan})\n",
    "    ### Clean IDIND index \n",
    "    df_tmp.IDIND = df_tmp.IDIND.astype(float)\n",
    "    df_tmp.IDFOYER = df_tmp.IDFOYER.astype(float)\n",
    "    \n",
    "    ### Filter mag clients\n",
    "    df_tmp = df_tmp[~df_tmp.IDIND.isin(clients_mag.IDIND)]\n",
    "\n",
    "    ### Filter non-french command with CODSOC\n",
    "    df_tmp = df_tmp.merge(df_codsoc, how = 'left', on = 'NUMCDE')\n",
    "    df_tmp = df_tmp[df_tmp.CODSOC==0]\n",
    "\n",
    "    #### Merge to get Mediane rev\n",
    "    df_tmp = df_tmp.merge(df_client, how = 'left', on = 'IDIND')\n",
    "\n",
    "    ### add departments and cohort\n",
    "    df_tmp = df_tmp.merge(df_client_dept.replace({'$null$': np.nan}), how = 'left', on = 'IDIND')\n",
    "    df_tmp = df_tmp[df_tmp.DATPREMCDEWEB != '$null$']\n",
    "    df_tmp['DATCDE'] = pd.to_datetime(df_tmp[\"DATCDE\"])\n",
    "    df_tmp['DATPREMCDEWEB'] = pd.to_datetime(df_tmp[\"DATPREMCDEWEB\"])\n",
    "    #df_tmp['DEPARTEMENT'] = df_tmp['CODPOST'].apply(lambda x : str(x)[:2])\n",
    "    df_tmp['COHORT'] = pd.to_datetime(df_tmp[\"DATPREMCDEWEB\"]).dt.year\n",
    "    \n",
    "    ### filter cohort\n",
    "    df_tmp = df_tmp[(df_tmp['COHORT'] >= 2017) & (df_tmp['COHORT'] < 2021)]\n",
    "    \n",
    "    ### filter on DN <= DB\n",
    "    df_tmp = df_tmp[df_tmp.DN <= df_tmp.DBI]\n",
    "    df_tmp = df_tmp[df_tmp.DN >= 0]\n",
    "\n",
    "    df = pd.concat([df,df_tmp[['IDIND', 'DN', 'NUMCDE', 'DATCDE', 'DATPREMCDEWEB', 'DEPARTEMENT_NIV2', 'COHORT']]])\n",
    "  \n",
    "    del df_tmp\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### delete useless dataframes\n",
    "for x in [df_articles, df_codsoc, df_client_dept, clients_mag, df_client, df_IRIS_by_dep]:\n",
    "    del x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Exclude B2B clients\n",
    "df_b2b = pd.read_csv('./Vertbaudet/France/src/20211012_TB2B.csv')\n",
    "df_b2b[['IDIND', 'TB2B']] = df_b2b[['IDIND', 'TB2B']].astype(float)\n",
    "df = df.merge(df_b2b, how = 'left', on = 'IDIND')\n",
    "df = df[df['TB2B']==0]\n",
    "df = df.drop(columns = ['TB2B'])\n",
    "del df_b2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add ORDER_NUMBER\n",
    "nb_order =  flatten(df.sort_values(by='DATCDE',ascending=True).groupby(['NUMCDE']).agg({'IDIND':'first', 'DATCDE': 'first'}))\n",
    "nb_order['ORDER_NUMBER'] = nb_order.sort_values(by='DATCDE',ascending=True).groupby(['IDIND']).cumcount()+1\n",
    "df = pd.merge(df,nb_order[['NUMCDE','ORDER_NUMBER']],on='NUMCDE',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Client Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customer_category_attribution(x):\n",
    "    if x==1:\n",
    "        return 'One-timer'\n",
    "    if x==2:\n",
    "        return 'Two-timer'\n",
    "    else:\n",
    "        return 'Recurring'\n",
    "\n",
    "### Add CLIENT_CATEGORY\n",
    "nb_commande = flatten(df.groupby(['IDIND']).agg({'NUMCDE':pd.Series.nunique}))\n",
    "nb_commande.columns = ['IDIND','NB_ORDERS']\n",
    "df = pd.merge(df,nb_commande,on='IDIND',how='left',suffixes=(False,False))\n",
    "df['CLIENT_CATEGORY'] = df.NB_ORDERS.apply(lambda x: customer_category_attribution(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LTV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121.9110836696581\n",
      "150.33917873961332\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "from datetime import datetime, time ,date ,timedelta\n",
    "\n",
    "# Add DAT_12 and DAT_14 column\n",
    "df['DAT_12'] = df['DATPREMCDEWEB'] + timedelta(days=365)\n",
    "df['DAT_24'] = df['DATPREMCDEWEB'] + timedelta(days=730)\n",
    "\n",
    "### Add LTV_12 column\n",
    "df_ltv_12 = df[df['DATCDE']<=df['DAT_12']][['IDIND', 'DN']]\n",
    "df_ltv_12 = df_ltv_12.groupby('IDIND').agg({'DN': sum})\n",
    "df_ltv_12 = df_ltv_12.rename(columns = {'DN': 'LTV_12'})\n",
    "print(df_ltv_12['LTV_12'].mean())\n",
    "df = df.merge(df_ltv_12, how = 'left', on = 'IDIND')\n",
    "\n",
    "del df_ltv_12\n",
    "\n",
    "### Add LTV_24 column\n",
    "df_ltv_24 = df[df['DATCDE']<=df['DAT_24']][['IDIND', 'DN']]\n",
    "df_ltv_24 = df_ltv_24.groupby('IDIND').agg({'DN': sum})\n",
    "df_ltv_24 = df_ltv_24.rename(columns = {'DN': 'LTV_24'})\n",
    "print(df_ltv_24['LTV_24'].mean())\n",
    "df = df.merge(df_ltv_24, how = 'left', on = 'IDIND')\n",
    "\n",
    "del df_ltv_24\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Churn_delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Add churn_delay field\n",
    "df_churn = df.sort_values(by = 'DATCDE', ascending = True).groupby('IDIND').agg({'DATCDE': 'last', 'DATPREMCDEWEB': 'last', 'IDIND':'last'})\n",
    "df_second = df[df['ORDER_NUMBER'] == 2].drop_duplicates('IDIND')[['IDIND', 'DATCDE']].rename(columns = {'DATCDE': 'DATCDE_2'})\n",
    "df_churn = df_churn.merge(df_second, how = 'left', left_index = True,  right_on = 'IDIND')\n",
    "df_churn = df_churn.reset_index()\n",
    "df_churn['CHURN_DELAY'] = (df_churn['DATCDE'] + timedelta(days=365)) - df_churn['DATPREMCDEWEB']\n",
    "df_churn['CHURN_DELAY_2'] = (df_churn['DATCDE'] + timedelta(days=365)) - df_churn['DATCDE_2']\n",
    "df_churn = df_churn.drop(columns = 'index')\n",
    "\n",
    "df = df.merge(df_churn[['IDIND','CHURN_DELAY_2', 'CHURN_DELAY']], how = 'left', left_on = 'IDIND', right_on  = 'IDIND')\n",
    "\n",
    "del df_churn\n",
    "del df_second\n",
    "\n",
    "df['CHURN_DELAY'] = df['CHURN_DELAY'].apply(lambda x : x.days)\n",
    "df['CHURN_DELAY_2'] = df['CHURN_DELAY_2'].apply(lambda x : x.days)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recruitment departmenent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "318"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Add DEPARTEMENT_CMD field\n",
    "cat_order = df.groupby(['NUMCDE', 'DEPARTEMENT_NIV2']).agg({'DN': sum, 'DEPARTEMENT_NIV2': 'first'})\n",
    "cat_order = cat_order.sort_values(by='DN',ascending=False).groupby('NUMCDE').agg({'DEPARTEMENT_NIV2': 'first'})\n",
    "cat_order = cat_order.rename(columns = {'DEPARTEMENT_NIV2': 'DEPARTEMENT_CMD'})\n",
    "\n",
    "df = pd.merge(df,cat_order, how='left', on='NUMCDE', right_index = False,  suffixes=(False,False))\n",
    "\n",
    "del cat_order\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add DEPARTEMENT_FIRST (majority department of first command)\n",
    "cat_rec = df.sort_values(by='DATCDE',ascending=True).drop_duplicates(subset='IDIND', keep='first', inplace=False)[['IDIND','DEPARTEMENT_CMD']]\n",
    "cat_rec.columns = ['IDIND','DEPARTEMENT_FIRST']\n",
    "df = pd.merge(df,cat_rec,on='IDIND',how='left',suffixes=(False,False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recruitment month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MONTH_RECRUITMENT'] = pd.to_datetime(df['DATPREMCDEWEB']).dt.month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add SEGMENT column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_seg = pd.read_csv('./Vertbaudet/France/src/SEGFR.CSV')\n",
    "df = df.merge(df_seg.drop_duplicates(['IDIND', 'NUMCDE']), how = 'left', on = ['IDIND', 'NUMCDE'])\n",
    "\n",
    "del df_seg\n",
    "\n",
    "df = df.drop(columns = ['DATCDE_y', 'Unnamed: 0']).rename(columns = {'DATCDE_x': 'DATCDE'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Group VB segments to create Personna segments 'SEG_SMALL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_segment = {'MP_GARCON': 'ENFANT', 'FM_MULTI': 'FM', 'FM_PRIMI': 'FM', 'MM_AUTRE': 'OTHER', 'BB': 'BB',\n",
    "       'MP_FILLE': 'ENFANT', 'MP_MIXTE': 'ENFANT', 'ADOMP': 'ENFANT', 'MPBB': 'BB', 'ADO': 'ENFANT', 'ADOMPBB': 'BB', 'ADOBB': 'BB',\n",
    "       'MM_KDO': 'KDO'}\n",
    "\n",
    "def map_seg_small(x) : \n",
    "    if isinstance(x, str):\n",
    "        return dict_segment[x]\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SEG_SMALL'] = df['SEGMENT'].apply(map_seg_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['SEG_SMALL', 'DEPARTEMENT_NIV2'])['DN'].sum().unstack().to_excel('./Vertbaudet/France/Output/'+today+'_dn_by_univ_by_segment.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Churn & LTV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(['IDIND', 'SEG_SMALL']).groupby(['SEG_SMALL']).agg({'LTV_12': 'mean', 'LTV_24': 'mean', 'CHURN_DELAY': 'mean'}).to_excel('./Vertbaudet/France/Output/'+today+'_ltv_churn_by_univ_by_segment.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Recruit dept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(['IDIND', 'SEG_SMALL']).groupby(['SEG_SMALL', 'DEPARTEMENT_FIRST']).agg({'IDIND': pd.Series.nunique}).unstack().to_excel('./Vertbaudet/France/Output/'+today+'_recruit_dept_by_univ_by_segment.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Client Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(['IDIND', 'SEG_SMALL']).groupby(['SEG_SMALL', 'CLIENT_CATEGORY']).agg({'IDIND': pd.Series.nunique}).unstack().to_excel('./Vertbaudet/France/Output/'+today+'_client_cat_by_segment.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Recruitment month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(['IDIND', 'SEG_SMALL']).groupby(['SEG_SMALL', 'MONTH_RECRUITMENT']).agg({'IDIND': pd.Series.nunique}).unstack().to_excel('./Vertbaudet/France/Output/'+today+'_recruit_month_by_segment.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- DN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('SEG_SMALL')['DN'].sum().to_excel('./Vertbaudet/France/Output/'+today+'_dn_by_segment.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Average number of order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('IDIND').agg({'NUMCDE': pd.Series.nunique, 'SEG_SMALL': 'first'}).groupby('SEG_SMALL').agg({'NUMCDE': 'mean'}).to_excel('./Vertbaudet/France/Output/'+today+'_avg_nb_order_by_segment.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Number of order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('SEG_SMALL').agg({'NUMCDE': pd.Series.nunique}).to_excel('./Vertbaudet/France/Output/'+today+'_nb_order_by_segment.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
